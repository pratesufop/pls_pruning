{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89809c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "import os\n",
    "import tensorflow\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "tensorflow.random.set_seed(123)\n",
    "\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = \"2\"\n",
    "\n",
    "\n",
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90572d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv0 (Conv2D)              (None, 28, 28, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 14, 14, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 7, 7, 64)          18496     \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 64)               0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,946\n",
      "Trainable params: 23,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0636 - accuracy: 0.9785\n",
      "23946\n",
      "[16, 25, 59]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv0 (Conv2D)              (None, 28, 28, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 14, 14, 25)        3625      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 25)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 7, 7, 59)          13334     \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 59)               0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 59)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                600       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,719\n",
      "Trainable params: 17,719\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0555 - accuracy: 0.9818\n",
      "17719\n",
      "[16, 16, 58]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv0 (Conv2D)              (None, 28, 28, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 14, 14, 16)        2320      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 7, 7, 58)          8410      \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 58)               0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 58)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                590       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,480\n",
      "Trainable params: 11,480\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0547 - accuracy: 0.9823\n",
      "11480\n",
      "[16, 11, 54]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv0 (Conv2D)              (None, 28, 28, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 14, 14, 11)        1595      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 11)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 7, 7, 54)          5400      \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 54)               0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 54)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                550       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,705\n",
      "Trainable params: 7,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0558 - accuracy: 0.9821\n",
      "7705\n",
      "[16, 9, 47]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv0 (Conv2D)              (None, 28, 28, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 14, 14, 9)         1305      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 9)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 7, 7, 47)          3854      \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 47)               0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 47)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                480       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,799\n",
      "Trainable params: 5,799\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0522 - accuracy: 0.9835\n",
      "5799\n",
      "[12, 9, 43]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x7fdda80cdcd0>,\n",
       "  <matplotlib.axis.XTick at 0x7fdda80cda30>,\n",
       "  <matplotlib.axis.XTick at 0x7fdda80cdfa0>,\n",
       "  <matplotlib.axis.XTick at 0x7fdda85eac40>,\n",
       "  <matplotlib.axis.XTick at 0x7fdda85eab50>],\n",
       " [Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, '')])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_absolute_rank(model,layer_names, p):\n",
    "    scores = []\n",
    "    for l in layer_names:\n",
    "        nf = model.get_layer(l).weights[0].shape[-1]\n",
    "        scores.extend(np.mean(np.abs(model.get_layer(l).weights[0].numpy()).reshape([-1,nf]), axis=0))\n",
    "    \n",
    "    idx = np.argsort(scores)[::-1][:int(len(scores)*(1-p))]\n",
    "    \n",
    "    return idx\n",
    "\n",
    "def get_importance_rank(model, x_train, y_train, p):\n",
    "    # getting the feature representation for all training samples\n",
    "    c1, c2, c3 = model.predict(x_train)\n",
    "    \n",
    "    # concatenating\n",
    "    filters_response = np.concatenate([c1,c2,c3], axis=-1)\n",
    "    \n",
    "    # fitting the PLS model\n",
    "    pls2 = PLSRegression(n_components=2)\n",
    "    pls2.fit(filters_response, np.argmax(y_train, axis=1))\n",
    "    \n",
    "    # computing the vip score\n",
    "    vip_scores = vip(pls2)\n",
    "    \n",
    "    # the filters that we want to keep\n",
    "    idx = np.argsort(vip_scores)[::-1][:int(len(vip_scores)*(1-p))]\n",
    "    \n",
    "    return idx\n",
    "\n",
    "def get_output_names(multiple_model):\n",
    "    output_names = []\n",
    "    for idx,l in enumerate(multiple_model.outputs):\n",
    "        output_names.extend(['conv%d_%d' % (idx,ni) for ni in np.arange(l.shape[1])])\n",
    "\n",
    "    output_names = np.array(output_names)\n",
    "    return output_names\n",
    "\n",
    "# computing the PLS Vip importance\n",
    "def vip(model):\n",
    "    t = model.x_scores_\n",
    "    w = model.x_weights_\n",
    "    q = model.y_loadings_\n",
    "    p, h = w.shape\n",
    "    vips = np.zeros((p,))\n",
    "    s = np.diag(t.T @ t @ q.T @ q).reshape(h, -1)\n",
    "    total_s = np.sum(s)\n",
    "    for i in range(p):\n",
    "        weight = np.array([ (w[i,j] / np.linalg.norm(w[:,j]))**2 for j in range(h) ])\n",
    "        vips[i] = np.sqrt(p*(s.T @ weight)/total_s)\n",
    "    return vips\n",
    "\n",
    "def get_model(input_shape, num_classes, num_filters, mode = 'max'):\n",
    "    \n",
    "    # Model\n",
    "    img = keras.Input(shape=input_shape)\n",
    "    x = img\n",
    "    conv_outs = []\n",
    "    for idx,f in enumerate(num_filters):\n",
    "        x1 = layers.Conv2D(f, kernel_size=(3, 3), activation=\"relu\", name = \"conv%d\" % idx, padding=\"same\")(x) # , kernel_regularizer = keras.regularizers.l1_l2(l1=0.0001, l2=0.0001)\n",
    "        x = layers.MaxPooling2D(2)(x1)\n",
    "        if mode == 'max':\n",
    "            x1 = layers.GlobalMaxPooling2D()(x1)\n",
    "        if mode == 'avg':\n",
    "            x1 = layers.GlobalAveragePooling2D()(x1)\n",
    "            \n",
    "        conv_outs.append(x1)\n",
    "    \n",
    "\n",
    "    x = layers.Dropout(0.5, name = \"dropout\")(x1)\n",
    "    out = layers.Dense(num_classes, activation=\"softmax\",  name = \"dense\")(x)\n",
    "    \n",
    "    model = keras.Model(inputs = img, outputs = out)\n",
    "\n",
    "    multiple_model = keras.Model(inputs = img, outputs = conv_outs)\n",
    "    \n",
    "    return model, multiple_model\n",
    "\n",
    "\n",
    "# paramters\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "# percentage of filters to remove at each iteration\n",
    "p = 0.1 \n",
    "# number of filters at each layer\n",
    "initial_filters = [16, 32, 64]\n",
    "\n",
    "# global pooling before pls\n",
    "mode = 'avg' # 'max'\n",
    "\n",
    "# num iterations\n",
    "num_iters = 5\n",
    "\n",
    "# method (PLS or ABS)\n",
    "method = 'pls' #'abs'\n",
    "filters_conv = initial_filters\n",
    "\n",
    "weights = {}\n",
    "layer_names = ['conv0', 'conv1', 'conv2']\n",
    "acc_test = []\n",
    "\n",
    "\n",
    "for iters in np.arange(num_iters):\n",
    "    \n",
    "    model, multiple_model = get_model(input_shape, num_classes, num_filters = filters_conv, mode = mode)\n",
    "    model.summary()\n",
    "    \n",
    "    if len(weights) > 0:\n",
    "        for l in layer_names:\n",
    "            model.get_layer(l).set_weights(weights[l]['weights'])\n",
    "            multiple_model.get_layer(l).set_weights(weights[l]['weights'])\n",
    "        \n",
    "        model.get_layer('dense').set_weights(weights['dense']['weights'])\n",
    "        weights = {}\n",
    "        \n",
    "    # training the model\n",
    "    if iters == 0:\n",
    "        opt = tensorflow.keras.optimizers.Adam(learning_rate=0.01)\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "        model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose = 0)\n",
    "    else:\n",
    "        opt = tensorflow.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "        model.fit(x_train, y_train, batch_size=batch_size, epochs=2, validation_split=0.1, verbose = 0)\n",
    "        \n",
    "    # evaluating the model\n",
    "    out_eval = model.evaluate(x_test, y_test)\n",
    "    acc_test.append(out_eval[1])\n",
    "    \n",
    "    num_filters_layer = []\n",
    "    \n",
    "    # computing the PLS VIP importance\n",
    "    \n",
    "    output_names = get_output_names(multiple_model)\n",
    "    if method == 'pls':\n",
    "        idx = get_importance_rank(multiple_model, x_train, y_train, p)\n",
    "    elif method == 'abs':\n",
    "        idx =  get_absolute_rank(model,layer_names, p)\n",
    "    \n",
    "        \n",
    "    lnames = np.array([l.split('_')[0] for l in output_names[idx]])\n",
    "    lpos = np.array([int(l.split('_')[1]) for l in output_names[idx]])\n",
    "    \n",
    "    prev_layer = [0]\n",
    "    for layer in layer_names:\n",
    "\n",
    "        w, b = model.get_layer(layer).get_weights()[0], model.get_layer(layer).get_weights()[1]\n",
    "        \n",
    "        num_filters_layer.append(np.sum(lnames == layer))\n",
    "        weights[layer] = {}\n",
    "        actual_layer = lpos[lnames == layer]\n",
    "        weights[layer]['weights'] = [w[:, : , prev_layer, :][:,:,:, actual_layer], b[actual_layer]]   \n",
    "        prev_layer = lpos[lnames == layer]\n",
    "    \n",
    "    print(model.count_params())\n",
    "    weights['dense'] = {}\n",
    "    weights['dense']['weights'] = [model.get_layer('dense').get_weights()[0][prev_layer,:], model.get_layer('dense').get_weights()[1]]\n",
    "    \n",
    "    filters_conv = list(num_filters_layer)\n",
    "\n",
    "\n",
    "    print(filters_conv)\n",
    "    del model\n",
    "    del multiple_model\n",
    "    \n",
    "    K.clear_session()\n",
    "    \n",
    "plt.plot(acc_test)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Test Acc.')\n",
    "plt.xticks(np.arange(len(acc_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e7acf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4fd822",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
